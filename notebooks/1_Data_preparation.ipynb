{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3f61a76",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "**beatit.ai** is one of the a music streaming startup in South Asia. \n",
    "They offer their services to millions of people, supported by advertising and paid subscriptions. It uses free or discounted trials to entice a customer who arrives on their platform. However, with the arrival of some new competitors the company’s churn rate is rising high. \n",
    "\n",
    "The task at hand is to predict the propensity of customer churn for the company. In the project, we would like to build a model which can predict in advance the customers who are at risk to cancel the beatit.ai music streaming service based on available data which is the user's past activity and interaction logs with the service. \n",
    "\n",
    "This will assist in identifying the probability of customer churn in the future so that preventive action can be taken proactively. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b320e2",
   "metadata": {},
   "source": [
    "# 1. Data Preparation\n",
    "The first major task is to access and evaluate the data. The Data, to be used is coming from several sources and contains information about each user's subscription and streaming activities.\n",
    "\n",
    "1.   User Profile data: **members.csv**. This data includes the user persona like user’s age, city and their registration time.\n",
    "2.   User Logs data: **user_logs.csv**. This data consist of each user's listening behaviour in terms of their songs played in each day\n",
    "3.   User Transaction data:  **transations.csv**. This data consist of details like payment method or whether the subscription was cancelled.\n",
    "4.   Historical data: **train.csv** . This data consists of user IDs and whether these users have churned or not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61c4a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function\n",
    "import os\n",
    "import sys\n",
    "\n",
    "new_directory = \"E:/airflow/airflow\"\n",
    "current_directory = os.getcwd()\n",
    "scripts_path = os.path.abspath(os.path.join(os.getcwd(), '../scripts'))\n",
    "\n",
    "def change_directory(current_directory, new_directory,scripts_path):\n",
    "    # Get the current working directory\n",
    "    print(f'Current directory: {current_directory}')\n",
    "    # Define the path to change to\n",
    "    #new_directory = \"E:/airflow/airflow\"\n",
    "    try:\n",
    "        # Change the current working directory\n",
    "        os.chdir(new_directory)\n",
    "        # Verify the change\n",
    "        current_directory = os.getcwd()\n",
    "        print(f'Current directory changed to: {current_directory}')\n",
    "    except FileNotFoundError:\n",
    "        print(f'Error: The directory \"{new_directory}\" does not exist.')\n",
    "    except PermissionError:\n",
    "        print(f'Error: Permission denied to change to \"{new_directory}\".')\n",
    "    except Exception as e:\n",
    "        print(f'An unexpected error occurred: {e}')\n",
    "    # Add the scripts directory to the Python path\n",
    "    sys.path.append(scripts_path)\n",
    "\n",
    "    \n",
    "change_directory(current_directory, new_directory, scripts_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74066858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up all directory\n",
    "root_folder = new_directory\n",
    "database_path = root_folder+\"/database/\"\n",
    "data_directory = root_folder+\"/data/raw/\"\n",
    "data_profile_path = root_folder+\"/data/profile_report/\"\n",
    "intermediate_data_path = root_folder+\"/data/interim/\"\n",
    "final_processed_data_path = root_folder+\"/data/processed/\"\n",
    "\n",
    "old_data_directory = root_folder+\"/data/raw/\"\n",
    "new_data_directory = root_folder+\"/data/new/\"\n",
    "intermediate_path = root_folder+\"/data/interim/\"\n",
    "\n",
    "# Database\n",
    "db_path = root_folder+\"/database/\"\n",
    "db_file_name = \"feature_store_v01.db\"\n",
    "drfit_db_name = \"drift_db_name.db\"\n",
    "date_columns = ['registration_init_time','transaction_date_min','transaction_date_max','membership_expire_date_max','last_login']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccff603",
   "metadata": {},
   "source": [
    "### 1.1 Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c047d260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb73a46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from scripts.utils import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c543127f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ec78c4",
   "metadata": {},
   "source": [
    " ### 1.2 Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b662d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function is also available in utils.py\n",
    "\n",
    "# def load_data(file_path_list):\n",
    "#     data = []\n",
    "#     for eachfile in file_path_list:\n",
    "#         data.append(pd.read_csv(eachfile))\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb96baf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "members, user_logs, transactions, train  = load_data( [\n",
    "                                                            f\"{data_directory}members_profile.csv\",\n",
    "                                                            f\"{data_directory}userlogs.csv\",\n",
    "                                                            f\"{data_directory}transactions_logs.csv\",\n",
    "                                                            f\"{data_directory}churn_logs.csv\"\n",
    "                                                            ]\n",
    "                                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df5e804",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(members.shape)\n",
    "print(transactions.shape)\n",
    "print(user_logs.shape)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff1a5bf",
   "metadata": {},
   "source": [
    "Since there are four data scources, it is important to understand the distribution of each data before joining them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4edb195",
   "metadata": {},
   "outputs": [],
   "source": [
    "members.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d98ec15",
   "metadata": {},
   "source": [
    "The data is structured as:\n",
    "* msno\n",
    "* city\n",
    "* bd: age. Note: this column has outlier values ranging from -7000 to 2015, please use your judgement.\n",
    "* gender\n",
    "* registered_via: registration method\n",
    "* registration_init_time: format %Y%m%d\n",
    "* expiration_date: format %Y%m%d, taken as a snapshot at which the member.csv is extracted. Not representing the actual churn behavior.\n",
    "\n",
    " Note that not every user in the dataset is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6887485",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8307082a",
   "metadata": {},
   "source": [
    "The data is structured as:\n",
    "* msno: user id\n",
    "* payment_method_id: payment method\n",
    "* payment_plan_days: length of membership plan in days\n",
    "* plan_list_price: in New Taiwan Dollar (NTD)\n",
    "* actual_amount_paid: in New Taiwan Dollar (NTD)\n",
    "* is_auto_renew\n",
    "* transaction_date: format %Y%m%d\n",
    "* membership_expire_date: format %Y%m%d\n",
    "* is_cancel: whether or not the user canceled the membership in this transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2706b021",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total unique records: ',transactions.msno.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f466d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions[transactions['msno']==\"Qw6UVFUknPVOLxSSsejinxU/8a5/AgmiWMvPoEt0rik=\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3def196",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_logs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a8b4a4",
   "metadata": {},
   "source": [
    "The data is structured as:\n",
    "* msno: user id\n",
    "* date: format %Y%m%d\n",
    "* num_25: # of songs played less than 25% of the song length\n",
    "* num_50: # of songs played between 25% to 50% of the song length\n",
    "* num_75: # of songs played between 50% to 75% of of the song length\n",
    "* num_985: # of songs played between 75% to 98.5% of the song length\n",
    "* num_100: # of songs played over 98.5% of the song length\n",
    "* num_unq: # of unique songs played\n",
    "* total_secs: total seconds played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d8e0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total unique records: ',user_logs.msno.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7baf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc3bd8f",
   "metadata": {},
   "source": [
    "Here, the column **msno** represents the unique identity of a service subscriber. \n",
    "The transaction data provides the information of each subscriber and their transactional details with respect to the service they have subscribed to. Similarly the data in the user logs table provides information about each user and their streaming behaviour on a daily level.\n",
    "\n",
    "Here, the transaction and streaming logs are quite verbose with multiple records being recorded for a subscriber on a given date. On dates where there is no activity, no entries are found for a subscriber in these tables.\n",
    "\n",
    "Additionaly, certain information in the above data have been masked for privacy concerns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bf209c",
   "metadata": {},
   "source": [
    "> Definition of a **churned user**:\n",
    "A subscriber is identified as a churned user if he/she fails to renew their subscription within 30 days after their current membership expires.\n",
    "Upon inspecting the data, we can observe that a majority of beatit.ai's subscription length is 30 days, therefore it can be said that a lot of users re-subscribe every month."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c1d766",
   "metadata": {},
   "source": [
    " ### 1.2.1 Data conversion for memory reducton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8115983",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function is present in utils.py\n",
    "\n",
    "# def compress_dataframes(list_of_dfs):\n",
    "#     final_df = []\n",
    "#     for eachdf in list_of_dfs:\n",
    "#         original_size = (eachdf.memory_usage(index=True).sum())/ 1024**2\n",
    "#         int_cols = list(eachdf.select_dtypes(include=['int']).columns)\n",
    "#         float_cols = list(eachdf.select_dtypes(include=['float']).columns)\n",
    "#         for col in int_cols:\n",
    "#             if ((np.max(eachdf[col]) <= 127) and(np.min(eachdf[col] >= -128))):\n",
    "#                 eachdf[col] = eachdf[col].astype(np.int8)\n",
    "#             elif ((np.max(eachdf[col]) <= 32767) and(np.min(eachdf[col] >= -32768))):\n",
    "#                 eachdf[col] = eachdf[col].astype(np.int16)\n",
    "#             elif ((np.max(eachdf[col]) <= 2147483647) and(np.min(eachdf[col] >= -2147483648))):\n",
    "#                 eachdf[col] = eachdf[col].astype(np.int32)\n",
    "#             else:\n",
    "#                 eachdf[col] = eachdf[col].astype(np.int64)\n",
    "    \n",
    "#         for col in float_cols:\n",
    "#             eachdf[col] = eachdf[col].astype(np.float16)\n",
    "#         compressed_size = (eachdf.memory_usage(index=True).sum())/ 1024**2\n",
    "        \n",
    "#         final_df.append((eachdf,original_size,compressed_size))\n",
    "        \n",
    "#     return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4453b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "members_c, transactions_c, user_logs_c = compress_dataframes([members, transactions, user_logs])\n",
    "members = members_c[0]\n",
    "transactions = transactions_c[0]\n",
    "user_logs = user_logs_c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4550be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"members DF before compress was in MB ,\",members_c[1], \"and after compress , \", members_c[2])\n",
    "print(\"transactions DF before compress was in MB ,\",transactions_c[1], \"and after compress , \", transactions_c[2])\n",
    "print(\"user_logs DF before compress was in MB ,\",user_logs_c[1], \"and after compress , \", user_logs_c[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a1049c",
   "metadata": {},
   "source": [
    " ### 1.3 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a01f117",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function available in utils.py\n",
    "\n",
    "# def count_plot(dataframe, list_of_columns):\n",
    "#     final_plot = []\n",
    "#     for eachcol in list_of_columns:\n",
    "#         plt.figure(figsize=(15,5))\n",
    "#         unique_features = dataframe[eachcol].unique()\n",
    "#         if dataframe[eachcol].dtype =='int64':\n",
    "#             unique_features=sorted(unique_features)\n",
    "#         sns.countplot(x=eachcol, data=dataframe , order = unique_features)\n",
    "#         plt.xlabel(eachcol)\n",
    "#         plt.ylabel('Count')\n",
    "#         plt.title(\"Frequency plot of {} Count\".format(eachcol))\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191e5277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline   \n",
    "#if plots don't come, uncomment and run above cell one more time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8457e96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "count_plot(members, ['city','gender','registered_via'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f19631e",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "\n",
    "* There are total of 21 Cities Encoded ( there is no City \"2\" in the data set). \n",
    "* There are Class of \"3\", \"4\", \"7\", \"9\", \"11\",\"13\" listed as registration method.  \n",
    "\n",
    "Kindly note that there is additional \"10\", and \"16\" class of cities listed in Member Data set but there are missing when we merged the data set ( see below). \n",
    "*  There are almost equal percentage of Male and Female, but more than half of the data is missing in gender field. We have see how to fill the missing entries or label them as third category. \n",
    "\n",
    "> Details of Registration init time can't be explored without converting the column to datatime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5bec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function is also available in utils.py\n",
    "\n",
    "# def fix_time_in_df(dataframe, column_name, expand=False):\n",
    "#     if not expand:\n",
    "#         dataframe[column_name] = dataframe[column_name].astype('str')\n",
    "#         return pd.to_datetime(dataframe[column_name])\n",
    "#     else:\n",
    "#         dataframe_new = dataframe.copy()\n",
    "#         dataframe_new[column_name] = dataframe_new[column_name].astype('str')\n",
    "#         dataframe_new[column_name] = pd.to_datetime(dataframe_new[column_name])\n",
    "#         #Extracting the date time year component\n",
    "#         dataframe_new[f\"{column_name}_year\"] = pd.DatetimeIndex(dataframe_new[column_name]).year\n",
    "#         #Extracting the date time year component\n",
    "#         dataframe_new[f\"{column_name}_month\"] = pd.DatetimeIndex(dataframe_new[column_name]).month\n",
    "#         #Extracting the date time year component\n",
    "#         dataframe_new[f\"{column_name}_day\"] = pd.DatetimeIndex(dataframe_new[column_name]).day_name()\n",
    "      \n",
    "#         return dataframe_new\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1debede",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "members_new = fix_time_in_df(members, 'registration_init_time', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba49b106",
   "metadata": {},
   "outputs": [],
   "source": [
    "members_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001ef9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_plot(members_new,['registration_init_time_year','registration_init_time_month','registration_init_time_day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281fea2f",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "* Registration trend has increased yearly, though there was a dip in 2014. Due to data upto few months in 2017, there is a dip.\n",
    "* Registration monthly trends are high in year end and year starting months. In between there is a smooth valley formation.\n",
    "* Registration daily trends are high on weekends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4ffe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "members['registration_init_time'] = fix_time_in_df(members, 'registration_init_time', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02737af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "members.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8df363",
   "metadata": {},
   "source": [
    "### 1.3.1 EDA using Pandas Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461f13b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function is also available in utils.py\n",
    "# import time\n",
    "\n",
    "# def get_data_profile(dataframe,html_save_path, \n",
    "#                      embed_in_cell=True,take_sample=False, sample_frac=0.5, dataframe_name=\"data\"):\n",
    "#     if take_sample:\n",
    "#         dataframe = dataframe.sample(frac=sample_frac)\n",
    "#     if embed_in_cell:\n",
    "#         profile = ProfileReport(dataframe, title=f\"{dataframe_name} Data Summary Report\")\n",
    "#         return profile.to_notebook_iframe()\n",
    "#     else:\n",
    "#         profile = ProfileReport(dataframe, title=f\"{dataframe_name} Data Summary Report\")\n",
    "#         timestamp = str(int(time.time()))\n",
    "#         filename = f\"{dataframe_name}_data_profile_{timestamp}\"\n",
    "#         profile.to_file(html_save_path+filename+\".html\")\n",
    "#         return \"Your Data Profile has been saved at .. \",html_save_path+filename+\".html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d287b87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#taking sample\n",
    "get_data_profile(members,html_save_path=None, \n",
    "                     embed_in_cell=True,take_sample=True, sample_frac=0.01, \n",
    "                dataframe_name='Members')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020b8668",
   "metadata": {},
   "source": [
    "**Observations**:\n",
    "\n",
    "\n",
    "#Write your observations from the profile report created above\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd559be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "get_data_profile(train,html_save_path=None, \n",
    "                     embed_in_cell=True,take_sample=False, sample_frac=0.01, \n",
    "                dataframe_name='Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940ad167",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Convert all float16 columns to float32\n",
    "user_logs = user_logs.astype({col: 'float32' for col in user_logs.select_dtypes('float16').columns})\n",
    "\n",
    "get_data_profile(user_logs,html_save_path=data_profile_path, \n",
    "                     embed_in_cell=False,take_sample=True, sample_frac=0.001, \n",
    "                dataframe_name='user_logs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b011de9a",
   "metadata": {},
   "source": [
    "### 1.5 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704d87fb",
   "metadata": {},
   "source": [
    "#### Registration Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6ab709",
   "metadata": {},
   "outputs": [],
   "source": [
    "#these functions are available in utils.py\n",
    "\n",
    "# def get_data_describe(dataframe,round_num=2):\n",
    "#     return round(dataframe.describe(),round_num)\n",
    "\n",
    "# def get_data_na_values(dataframe, round_num=2):\n",
    "#     return pd.DataFrame({'%missing_values':round(dataframe.isna().sum()/dataframe.shape[0],round_num)})\n",
    "\n",
    "# def get_fill_na_dataframe(dataframe, column_name, value='mean'):\n",
    "#     if value != 'mean' and value !='mode':\n",
    "#         return dataframe[column_name].fillna(value)\n",
    "#     elif value == 'mean':\n",
    "#         value = dataframe[column_name].mean()\n",
    "#         return dataframe[column_name].fillna(value)\n",
    "#     elif value == 'mode':\n",
    "#         value = dataframe[column_name].mode()\n",
    "#         return dataframe[column_name].fillna(value)\n",
    "\n",
    "# def get_convert_column_dtype(dataframe, column_name, data_type='str'):\n",
    "#     if data_type == 'str':\n",
    "#         return dataframe[column_name].astype('str')\n",
    "#     elif data_type == 'int':\n",
    "#         return dataframe[column_name].astype('int')\n",
    "#     elif data_type == 'float':\n",
    "#         return dataframe[column_name].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75ca8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data_describe(members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81532d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data_na_values(members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdfb9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing missing values in gender\n",
    "members['gender'] = get_fill_na_dataframe(members, 'gender', value=\"others\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca6f0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "members.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62a6696",
   "metadata": {},
   "outputs": [],
   "source": [
    "members['registered_via'] = get_convert_column_dtype(members, 'registered_via', data_type='str')\n",
    "members['city'] = get_convert_column_dtype(members, 'city', data_type='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b19f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "members.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2dc755",
   "metadata": {},
   "outputs": [],
   "source": [
    "members.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3141f870",
   "metadata": {},
   "source": [
    "#### Transactional features\n",
    "\n",
    "The data here is present in one-many format, as one user can have multiple transaction samples. Therefore while joining the entire data, we need to convert the transactions data in one-one format.\n",
    "But before that let's format the data and process it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9916b527",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data_describe(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466389e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing Values\n",
    "get_data_na_values(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7a36e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "transactions['transaction_date'] = utils.fix_time_in_df(transactions, 'transaction_date', expand=False)\n",
    "transactions['membership_expire_date'] = utils.fix_time_in_df(transactions, 'membership_expire_date', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238c44ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55159743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#these functions are also available in utils.py\n",
    "\n",
    "# def get_groupby(dataframe, by_column, agg_dict=None, agg_func = 'mean', simple_agg_flag=True, reset_index=True):\n",
    "#     if reset_index:\n",
    "#         if simple_agg_flag:\n",
    "#             return dataframe.groupby(by_column).agg(agg_func).reset_index()\n",
    "#         else:\n",
    "#             return dataframe.groupby(by_column).agg(agg_dict).reset_index()\n",
    "#     else:\n",
    "#         if simple_agg_flag:\n",
    "#             return dataframe.groupby(by_column).agg(agg_func)\n",
    "#         else:\n",
    "#             return dataframe.groupby(by_column).agg(agg_dict)\n",
    "        \n",
    "# def get_merge(dataframe1, dataframe2, on, axis=1, how='inner'):\n",
    "#     return dataframe1.merge(dataframe2, on=on,how=how)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61728f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_base = get_groupby(transactions,'msno', agg_dict=None, agg_func = 'mean', simple_agg_flag=True, reset_index=True)\n",
    "transaction_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318aa13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dict = { 'transaction_date':'max', 'membership_expire_date':'max' }\n",
    "transaction_date = get_groupby(transactions,'msno', agg_dict=agg_dict, agg_func = 'mean', simple_agg_flag=False, reset_index=True)\n",
    "transaction_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6f3aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_final = get_merge(transaction_base, transaction_date, on = 'msno') \n",
    "transaction_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2a5f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data_describe(transaction_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cce6c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "get_data_profile(transaction_final,html_save_path=None, \n",
    "                     embed_in_cell=True,take_sample=False, sample_frac=0.01, \n",
    "                dataframe_name='Transaction_Final')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c38963e",
   "metadata": {},
   "source": [
    "**Observations**:\n",
    "\n",
    "\n",
    "#Write your observations from the profile report created above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1289747d",
   "metadata": {},
   "source": [
    "#### User Behavioural Features\n",
    "\n",
    "Like the transactions data, the data here is also present in one-many format.  Therefore this data also has to converted in one-one format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892e4a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data_describe(user_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6442e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing Values\n",
    "get_data_na_values(user_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c177bf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function is also available in utils.py \n",
    "\n",
    "# def get_fix_skew_with_log(dataframe, columns, replace_inf = True, replace_inf_with = 0):\n",
    "#     if replace_inf:\n",
    "#         dataframe_log = np.log(dataframe[columns]).replace([np.inf, -np.inf], replace_inf_with)\n",
    "#         return pd.concat([dataframe_log, dataframe.drop(columns,axis=1)], axis=1)\n",
    "#     else:\n",
    "#         dataframe_log = np.log(dataframe[columns])\n",
    "#         return pd.concat([dataframe_log, dataframe.drop(columns,axis=1)], axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3339f94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_logs_transformed = get_fix_skew_with_log(user_logs, ['num_25','num_50','num_75','num_985','num_100','num_unq','total_secs'], \n",
    "                                              replace_inf = True, replace_inf_with = 0)\n",
    "user_logs_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84b9f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data_describe(user_logs_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802da015",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_logs_transformed.drop('date', axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae659f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_logs_transformed_final = get_groupby(user_logs_transformed,'msno', agg_dict=None, agg_func = 'mean', simple_agg_flag=True, reset_index=True)\n",
    "user_logs_transformed_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caa2e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "get_data_profile(user_logs_transformed_final,html_save_path=None, \n",
    "                     embed_in_cell=True,take_sample=False, sample_frac=0.01, \n",
    "                dataframe_name='user_logs_transformed_final')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b58b0d",
   "metadata": {},
   "source": [
    "**Observations**:\n",
    "\n",
    "\n",
    "#Write your observations from the profile report created above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dba9de",
   "metadata": {},
   "source": [
    "### 1.6 Joining the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2204ed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(members.shape)\n",
    "print(train.shape)\n",
    "print(transaction_final.shape)\n",
    "print(user_logs_transformed_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b6bb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_df_v01 = get_merge(members, train, on='msno', axis=1, how='inner')\n",
    "train_df_v02 = get_merge(train_df_v01, transaction_final, on='msno', axis=1, how='inner')\n",
    "train_df_final = get_merge(train_df_v02, user_logs_transformed_final, on='msno', axis=1, how='inner')\n",
    "train_df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c0afc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns using a dictionary\n",
    "train_df_final = train_df_final.rename(columns={\n",
    "    'transaction_date_x': 'transaction_date_min',\n",
    "    'membership_expire_date_x': 'membership_expire_date_min',\n",
    "    'transaction_date_y': 'transaction_date_max',\n",
    "    'membership_expire_date_y': 'membership_expire_date_max'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15497255",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5068ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "get_data_profile(train_df_final,html_save_path=None, \n",
    "                     embed_in_cell=True,take_sample=False, sample_frac=0.01, \n",
    "                dataframe_name='train_df_final')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e30d7e",
   "metadata": {},
   "source": [
    "**Observations**:\n",
    "\n",
    "#Write your observations from the profile report created above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086c883c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#members_v01_sample_joinfinal.drop(['registration_init_time','date','transaction_date','membership_expire_date'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596891dc",
   "metadata": {},
   "source": [
    "### 1.6.1 Saving the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efb6b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function is also available in utils.py\n",
    "# import time\n",
    "# def get_save_intermediate_data(dataframe, path, filename=\"data_interim\"):\n",
    "#     filename = filename+\"_\"+str(int(time.time()))+\".csv\"\n",
    "#     dataframe.to_csv(path+filename)\n",
    "#     return \"Data Saved Here :\",path+filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f667ff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "get_save_intermediate_data(train_df_final, path=intermediate_data_path, filename=\"final_train_data_interim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d964026",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
