{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93b50593",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "When the performance of your model is not good, revisit your data. This is what we will do in this notebook. \n",
    "We will have a look at our data and try to engineer some features using which the model can use to improve its performance and stability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1bcc6a-05fd-4180-8129-23da592c739d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function\n",
    "import os\n",
    "import sys\n",
    "\n",
    "new_directory = \"E:/airflow/airflow\"\n",
    "current_directory = os.getcwd()\n",
    "scripts_path = os.path.abspath(os.path.join(os.getcwd(), '../scripts'))\n",
    "\n",
    "def change_directory(current_directory, new_directory,scripts_path):\n",
    "    # Get the current working directory\n",
    "    print(f'Current directory: {current_directory}')\n",
    "    # Define the path to change to\n",
    "  \n",
    "    try:\n",
    "        # Change the current working directory\n",
    "        os.chdir(new_directory)\n",
    "        # Verify the change\n",
    "        current_directory = os.getcwd()\n",
    "        print(f'Current directory changed to: {current_directory}')\n",
    "    except FileNotFoundError:\n",
    "        print(f'Error: The directory \"{new_directory}\" does not exist.')\n",
    "    except PermissionError:\n",
    "        print(f'Error: Permission denied to change to \"{new_directory}\".')\n",
    "    except Exception as e:\n",
    "        print(f'An unexpected error occurred: {e}')\n",
    "    # Add the scripts directory to the Python path\n",
    "    sys.path.append(scripts_path)\n",
    "\n",
    "    \n",
    "change_directory(current_directory, new_directory, scripts_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f46ea31-e789-4f52-9bc0-4c5477b624e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up all directory\n",
    "root_folder = new_directory\n",
    "database_path = root_folder+\"/database/\"\n",
    "data_directory = root_folder+\"/data/raw/\"\n",
    "data_profile_path = root_folder+\"/data/profile_report/\"\n",
    "intermediate_data_path = root_folder+\"/data/interim/\"\n",
    "final_processed_data_path = root_folder+\"/data/processed/\"\n",
    "\n",
    "old_data_directory = root_folder+\"/data/raw/\"\n",
    "new_data_directory = root_folder+\"/data/new/\"\n",
    "intermediate_path = root_folder+\"/data/interim/\"\n",
    "\n",
    "\n",
    "# Database\n",
    "db_path = root_folder+\"/database/\"\n",
    "db_file_name = \"feature_store_v01.db\"\n",
    "drfit_db_name = \"drift_db_name.db\"\n",
    "date_columns = ['registration_init_time','transaction_date_min','transaction_date_max','membership_expire_date_max','last_login']\n",
    "drift_db_name = \"drift_db_name.db\"\n",
    "\n",
    "# Mlflow\n",
    "mlflow_tracking_uri = \"http://Localhost:6006\"\n",
    "ml_flow_model_path = root_folder+ \"/mlruns/2/cb66e22bcbf74ded99dc219eb29e7609/artifacts/models/\"\n",
    "ml_flow_path = root_folder+ \"/mlruns/2/cb66e22bcbf74ded99dc219eb29e7609\"\n",
    "\n",
    "run_on = \"old\" #\"old\"\n",
    "append=False\n",
    "date_transformation = False\n",
    "start_date = '2017-03-01'\n",
    "end_date = '2017-03-31'\n",
    "mlflow_experiment_name = \"Model_Building_Pipeline_Drift\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e759c78c",
   "metadata": {},
   "source": [
    "### 1.1 Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d76487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9b055c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported Libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scripts.utils import *\n",
    "from pycaret.classification import *\n",
    "# Other Libraries\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486925ec",
   "metadata": {},
   "source": [
    " ### 1.2 Reading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365f8b14",
   "metadata": {},
   "source": [
    "We will be using the raw data for our analysis instead of the sampled one so that we can better judge the features that we create. But before moving on with our analysis it is advised to revisit that you revisit the EDA that we performed previously.\n",
    " \n",
    "* Recall that we had 4 categories of data, User Profile data, user logs, transactions, and historic data.\n",
    "* Here we will try to create features using that better represent the user’s engagement and the transaction that the user made.\n",
    "* But before that let’s load and clean the raw data.\n",
    "* Recall that during our preliminary analysis we found that the merging of the data was simply done as common aggregation. This needs to be improved primarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1153bd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#Reading the data\n",
    "#data pipeline \n",
    "\n",
    "members, user_logs, transactions, train  = load_data( [\n",
    "                                                            f\"{data_directory}members_profile.csv\",\n",
    "                                                            f\"{data_directory}userlogs.csv\",\n",
    "                                                            f\"{data_directory}transactions_logs.csv\",\n",
    "                                                            f\"{data_directory}churn_logs.csv\"\n",
    "                                                            ]\n",
    "                                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f4f722",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(members.shape)\n",
    "print(transactions.shape)\n",
    "print(user_logs.shape)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897bd799",
   "metadata": {},
   "source": [
    " ### 1.3 Data cleaning\n",
    "    \n",
    "Converting the columns to date-time column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b86cfd9-3b63-4097-95dd-c52bac0bd7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "members_c, transactions_c, user_logs_c = compress_dataframes([members, transactions, user_logs])\n",
    "members = members_c[0]\n",
    "\n",
    "transactions = transactions_c[0]\n",
    "user_logs = user_logs_c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26309013-df4a-4838-a42c-0ce5bfd13188",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"members DF before compress was in MB ,\",members_c[1], \"and after compress , \", members_c[2])\n",
    "print(\"transactions DF before compress was in MB ,\",transactions_c[1], \"and after compress , \", transactions_c[2])\n",
    "print(\"user_logs DF before compress was in MB ,\",user_logs_c[1], \"and after compress , \", user_logs_c[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce72988",
   "metadata": {},
   "source": [
    "### 1.4 Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c186463-9e2b-4e3d-aded-f1c5f0aaa001",
   "metadata": {},
   "source": [
    "##### 1.4.1 Members data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984fcc31-c63e-481c-9213-ac0160259c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "members.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a06984a-bacc-4c47-853e-e619620da222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #this function is also available in utils.py\n",
    "# def get_label_encoding_dataframe(dataframe, column_name, mapping_dict):\n",
    "#     return dataframe[column_name].map(mapping_dict) \n",
    "# # #average_age if (x <=0 or x >100) else x\n",
    "# def get_apply_condiiton_on_column(dataframe, column_name, condition):\n",
    "#     return dataframe[column_name].apply(lambda x :eval(condition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e468f18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#Replacing missing values in gender\n",
    "members['gender'] = get_fill_na_dataframe(members, 'gender', value=\"others\")\n",
    "\n",
    "gender_mapping = {'male':0,'female':1,'others':2}\n",
    "members['gender'] = get_label_encoding_dataframe(members, 'gender',gender_mapping)\n",
    "\n",
    "\n",
    "members['registered_via'] = get_convert_column_dtype(members, 'registered_via', data_type='str')\n",
    "members['city'] = get_convert_column_dtype(members, 'city', data_type='str')\n",
    "members['registration_init_time'] = fix_time_in_df(members, 'registration_init_time', expand=False)\n",
    "\n",
    "average_age = round(members['bd'].mean(),2)\n",
    "condition = f\"{average_age} if (x <=0 or x >100) else x\"\n",
    "members['bd'] = get_apply_condiiton_on_column(members, 'bd', condition)\n",
    "\n",
    "members.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a080bb-4afc-4877-9bec-e5e79cb09b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# observing the distribution of columns\n",
    "get_data_describe(members)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a59139f-973f-427b-819d-c7e356d0a624",
   "metadata": {},
   "source": [
    "##### 1.4.2 Transactions data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dbfc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#date conversion\n",
    "\n",
    "transactions['transaction_date'] = fix_time_in_df(transactions, 'transaction_date', expand=False)\n",
    "transactions['membership_expire_date'] = fix_time_in_df(transactions, 'membership_expire_date', expand=False)\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb382f7",
   "metadata": {},
   "source": [
    "### 2 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be133c3f",
   "metadata": {},
   "source": [
    "#### 2.1 Generating features from transactions data\n",
    "\n",
    "\n",
    "* **is_discount**\n",
    "Recall that in our dataset there are 2 columns named “plan_list_price” and “actual_amount_paid”. From here we can figure out if a user bought the plan at a discounted price or not by checking whether the amount paid by the user is smaller than the actual plan’s price or not. This feature is stored in “is_discount” where\n",
    "\t1 represents that the plan was bought at a discounted price\n",
    "\t0 represents that the plan was bought at the original price\n",
    "We will also store the discount that the user received in “discount”\n",
    " \n",
    "* **amt_per_day**\n",
    "We will now create a feature that calculates the per-day cost of a user’s subscription. It is expected that if the per-day cost of the subscription is high then the propensity of the user to churn increases. We will store this information in a column called “amt_per_day”.\n",
    " \n",
    "* **membership_duration**\n",
    "We also expect the older customer to have a lower probability to churn, thus we will create a feature “membership_duration” which will hold the number of months that the user has been a member of our platform.\n",
    " \n",
    "After creating and storing the above-mentioned features in “transactions.csv” we will generate a profile report for the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928ddab4-5f61-4c22-aac6-f4412bddccaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#these functions are also present in utils.py\n",
    "# def get_two_column_operations(dataframe, columns_1, columns_2, operator):\n",
    "#     if operator == \"+\":\n",
    "#         return dataframe[columns_1]+dataframe[columns_2]\n",
    "#     elif operator == \"-\":\n",
    "#         return dataframe[columns_1]-dataframe[columns_2]\n",
    "#     elif operator == \"/\":\n",
    "#         return dataframe[columns_1]/dataframe[columns_2]\n",
    "#     elif operator == \"*\":\n",
    "#         return dataframe[columns_1]*dataframe[columns_2]\n",
    "    \n",
    "# def get_timedelta_division(dataframe, column, td_type='D'):\n",
    "#     return dataframe[column] /np.timedelta64(1,td_type)\n",
    "\n",
    "# def get_replace_value_in_df(dataframe, column, value, replace_with):\n",
    "#     return dataframe[column].replace(value,replace_with) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d43d28-e927-475d-91dc-fba1938e3e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "transactions['discount'] =  get_two_column_operations(transactions, 'plan_list_price', 'actual_amount_paid', \"-\")\n",
    "\n",
    "condition = f\"1 if x > 0 else 0\"\n",
    "transactions['is_discount'] = get_apply_condiiton_on_column(transactions, 'discount', condition)\n",
    "\n",
    "\n",
    "transactions['amt_per_day'] = get_two_column_operations(transactions, 'actual_amount_paid', 'payment_plan_days', \"/\")\n",
    "transactions['amt_per_day'] = get_replace_value_in_df(transactions, 'amt_per_day', [np.inf, -np.inf], replace_with=0)\n",
    "\n",
    "\n",
    "transactions['membership_duration'] = get_two_column_operations(transactions, 'membership_expire_date', 'transaction_date', \"-\")\n",
    "transactions['membership_duration'] = get_timedelta_division(transactions, \"membership_duration\", td_type='D')\n",
    "transactions['membership_duration'] = get_convert_column_dtype(transactions, 'membership_duration', data_type='int')\n",
    "\n",
    "condition = f\"1 if x>30 else 0\"\n",
    "transactions['more_than_30'] = get_apply_condiiton_on_column(transactions, 'membership_duration', condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a137d9dd-89d9-4b63-81fb-bf9233535eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a847e7d7-9da2-49f3-b404-9893b4630749",
   "metadata": {},
   "source": [
    "We will apply different aggregation techniques on each column to derive additional features to map the relationship between independent and dependent vairables better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad116ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = {'payment_method_id':['count','nunique'], # How many transactions user had done in past, captures if payment method is changed\n",
    "       'payment_plan_days':['mean', 'nunique'] , #Average plan of customer in days, captures how many times plan is changed\n",
    "       'plan_list_price':'mean', # Average amount charged on user\n",
    "       'actual_amount_paid':'mean', # Average amount paid by user\n",
    "       'is_auto_renew':['mean','max'], # Captures if user changed its auto_renew state\n",
    "       'transaction_date':['min','max','count'], # First and the last transaction of a user\n",
    "       'membership_expire_date':'max' , # Membership exipry date of the user's last subscription\n",
    "       'is_cancel':['mean','max'], # Captures the average value of is_cancel and to check if user changed its is_cancel state\n",
    "       'discount' : 'mean', # Average discount given to customer\n",
    "       'is_discount':['mean','max'], # Captures the average value of is_discount and to check if user was given any discount in the past\n",
    "       'amt_per_day' : 'mean', # Average amount a user spends per day\n",
    "       'membership_duration' : 'mean' ,# Average membership duration \n",
    "       'more_than_30' : 'sum' #Flags if the difference in days if more than 30\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3233b8-baf6-4436-8676-f9309e8899dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_features = get_groupby(transactions, by_column='msno', agg_dict=agg, agg_func = 'mean', simple_agg_flag=False, reset_index=True)\n",
    "transactions_features.columns= transactions_features.columns.get_level_values(0)+'_'+transactions_features.columns.get_level_values(1)\n",
    "transactions_features.rename(columns = {'msno_':'msno','payment_plan_days_nunique':'change_in_plan', 'payment_method_id_count':'total_payment_channels',\n",
    "                                        'payment_method_id_nunique':'change_in_payment_methods','is_cancel_max':'is_cancel_change_flag',\n",
    "                                        'is_auto_renew_max':'is_autorenew_change_flag','transaction_date_count':'total_transactions'}, inplace = True)\n",
    "transactions_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4042cd89-5eec-41eb-b838-9e9a8ae605f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2080d07",
   "metadata": {},
   "source": [
    "#### 2.2 Generating features from user profiles\n",
    "\n",
    "Here we will engineer features that will better represent a user’s behavior. We will try to measure the users engagement with the platform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2338994e",
   "metadata": {},
   "source": [
    "* **login_frequency**\n",
    "A decent way to quantize a user’s engagement will be to simply check the number of times the user has used the platform in a given period of time. We create this feature and store this in “login_frequency”. We expect that a user who is engaged with the platform will have less propensity to churn.\n",
    " \n",
    "* **last_login**\n",
    "A user who is not active recently has more propensity to churn. We create a feature that checks the last login of a user and store it in \"last_login column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630ec865-4ff3-46cf-92c7-8708629d8f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_logs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56536820-445b-4308-8e12-e0c15d0ea371",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data_describe(user_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ab6e05-b799-44db-826c-87a5d3731932",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_logs['date'] =  fix_time_in_df(user_logs, column_name='date', expand=False)\n",
    "user_logs_transformed = get_fix_skew_with_log(user_logs, ['num_25','num_50','num_75','num_985','num_100','num_unq','total_secs'], \n",
    "                                              replace_inf = True, replace_inf_with = 0)\n",
    "user_logs_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb1d1c8-2645-412d-8080-cd62a56f7efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data_describe(user_logs_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b33714a-dec2-4a72-8e92-02efc3dcf6b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_logs_transformed_base = get_groupby(user_logs_transformed,'msno', agg_dict=None, agg_func = 'mean', simple_agg_flag=True, reset_index=True)\n",
    "user_logs_transformed_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267906c8-2f70-4332-b7fe-f300c7ef4d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dict = { 'date':['count','max'] }\n",
    "user_logs_transformed_dates = get_groupby(user_logs_transformed,'msno', agg_dict=agg_dict, agg_func = 'mean', simple_agg_flag=False, reset_index=True)\n",
    "user_logs_transformed_dates.columns = user_logs_transformed_dates.columns.droplevel()\n",
    "user_logs_transformed_dates.rename(columns = {'count':'login_freq', 'max': 'last_login'}, inplace = True)\n",
    "user_logs_transformed_dates.reset_index(inplace=True)\n",
    "user_logs_transformed_dates.drop('index',inplace=True,axis=1)\n",
    "user_logs_transformed_dates.columns = ['msno','login_freq','last_login']\n",
    "user_logs_transformed_dates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3e6490-45cd-47bd-858a-ce2cb9455440",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_logs_final = get_merge(user_logs_transformed_base, user_logs_transformed_dates, on = 'msno') \n",
    "user_logs_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e1d4e7-d613-489d-9a7c-0ebea9abc9a4",
   "metadata": {},
   "source": [
    "### Joining the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8c324a-899f-4a54-9e62-790eb3c005c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(members.shape)\n",
    "print(train.shape)\n",
    "print(transactions_features.shape)\n",
    "print(user_logs_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5b6e20-9864-46c6-85dd-58c399c6c643",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_df_v01 = get_merge(members, train, on='msno', axis=1, how='inner')\n",
    "train_df_v02 = get_merge(train_df_v01, transactions_features, on='msno', axis=1, how='inner')\n",
    "train_df_final = get_merge(train_df_v02, user_logs_final, on='msno', axis=1, how='inner')\n",
    "train_df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e91c48-0e06-4812-abc9-a68f383f4d04",
   "metadata": {},
   "source": [
    "#### Registration Duration\n",
    "* It is important to understand how long the customer has been part of the system. We can calculate it using the columns 'membership_expire_date_max' &  'registration_init_time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb18fbe6-9f1e-406f-b6af-8acaf593365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_final['registration_duration'] = get_two_column_operations(train_df_final, 'membership_expire_date_max', 'registration_init_time', \"-\")\n",
    "train_df_final['registration_duration'] = get_timedelta_division(train_df_final, \"registration_duration\", td_type='D')\n",
    "train_df_final['registration_duration'] = get_convert_column_dtype(train_df_final, 'registration_duration', data_type='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9c8b95-d52b-48f6-ba7b-9f921cdd176f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585db0cc-ba66-4717-9709-75e1ca63473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "get_data_profile(train_df_final,html_save_path=None, \n",
    "                     embed_in_cell=True,take_sample=False, sample_frac=0.01, \n",
    "                dataframe_name='train_df_final')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aafe95-c150-488d-bfce-23d319c3ab0c",
   "metadata": {},
   "source": [
    "### Saving the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818d6f41-83e8-4bd8-82ad-e4e3e8e745f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "get_save_intermediate_data(train_df_final, path=final_processed_data_path, filename=\"final_train_data_process\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
